{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wLIJmwoKxzfj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.datasets.folder import default_loader\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "(Onle applicable for google colab to fix some issues)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4tVKFn11G5b"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "checkpoint_path = os.path.join(\"train\", \".ipynb_checkpoints\")\n",
        "if os.path.exists(checkpoint_path):\n",
        "    shutil.rmtree(checkpoint_path)\n",
        "\n",
        "checkpoint_path = os.path.join(\"test\", \".ipynb_checkpoints\")\n",
        "if os.path.exists(checkpoint_path):\n",
        "    shutil.rmtree(checkpoint_path)\n",
        "\n",
        "checkpoint_path = os.path.join(\"validation\", \".ipynb_checkpoints\")\n",
        "if os.path.exists(checkpoint_path):\n",
        "    shutil.rmtree(checkpoint_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0V-KgXDzzKy"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "val_test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "train_dir = \"train\"\n",
        "test_dir = \"test\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TF4EsoXqzzIJ",
        "outputId": "76ea5188-92a8-4a1d-e7f8-b24b2c857466"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class distribution: Counter({0: 700, 1: 700})\n"
          ]
        }
      ],
      "source": [
        "full_dataset = datasets.ImageFolder(root=train_dir, transform=train_transform)\n",
        "\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
        "val_dataset.dataset.transform = val_test_transform\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-8yKI67zzFn",
        "outputId": "8bebbc5e-6126-4452-8666-080115f54a24"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 197MB/s]\n"
          ]
        }
      ],
      "source": [
        "model = models.resnet50(weights='DEFAULT')\n",
        "model.fc = nn.Linear(model.fc.in_features, 1)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "\n",
        "early_stopping_patience = 5\n",
        "best_val_loss = float('inf')\n",
        "patience_counter = 0\n",
        "num_epochs = 20\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Optmizers, loss and early stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nQ1hPMWXzzC8"
      },
      "outputs": [],
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, weight_decay=1e-4)\n",
        "scheduler = StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n",
        "#Eearly stopping\n",
        "early_stopping_patience = 5\n",
        "best_val_loss = float('inf')\n",
        "patience_counter = 0\n",
        "num_epochs = 20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQumXRYEzy_4",
        "outputId": "a14f814b-9bfc-4e54-b928-f3358ecf2e4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Train Loss: 9.5753, Val Loss: 0.3537, Val Acc: 0.8857\n",
            "Epoch 2, Train Loss: 2.9231, Val Loss: 0.0682, Val Acc: 0.9821\n",
            "Epoch 3, Train Loss: 2.7341, Val Loss: 0.1843, Val Acc: 0.9536\n",
            "Epoch 4, Train Loss: 0.6082, Val Loss: 0.0243, Val Acc: 0.9964\n",
            "Epoch 5, Train Loss: 0.2080, Val Loss: 0.0087, Val Acc: 0.9964\n",
            "Epoch 6, Train Loss: 0.1514, Val Loss: 0.0196, Val Acc: 0.9929\n",
            "Epoch 7, Train Loss: 0.8212, Val Loss: 0.0336, Val Acc: 0.9964\n",
            "Epoch 8, Train Loss: 0.8710, Val Loss: 0.0320, Val Acc: 0.9929\n",
            "Epoch 9, Train Loss: 0.1634, Val Loss: 0.0138, Val Acc: 0.9964\n",
            "Epoch 10, Train Loss: 0.0546, Val Loss: 0.0167, Val Acc: 0.9964\n",
            "Early stopping triggered.\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device).float()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images).squeeze(1)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device).float()\n",
        "\n",
        "            outputs = model(images).squeeze(1)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            preds = (torch.sigmoid(outputs) > 0.5).long()\n",
        "            correct += (preds.cpu() == labels.cpu().long()).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "    val_accuracy = correct / total\n",
        "    print(f\"Epoch {epoch+1}, Train Loss: {running_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
        "\n",
        "    # Early stopping\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), \"Model.pth\")\n",
        "        patience_counter = 0\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= early_stopping_patience:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    scheduler.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGHz2t01zy8G",
        "outputId": "dcf275e1-b50a-4836-c876-fcf4d7e8d692"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Found 80 test images.\n",
            "File: 40.jpg | Predicted: Healthy | Actual: Healthy | ✔\n",
            "File: S_75.jpg | Predicted: Sick | Actual: Sick | ✔\n",
            "File: 38.jpg | Predicted: Healthy | Actual: Healthy | ✔\n",
            "File: S_67.jpg | Predicted: Sick | Actual: Sick | ✔\n",
            "File: S_55.jpg | Predicted: Sick | Actual: Sick | ✔\n",
            "File: 3.jpg | Predicted: Sick | Actual: Healthy | ✘\n",
            "File: 34.jpg | Predicted: Sick | Actual: Healthy | ✘\n",
            "File: 16.jpg | Predicted: Healthy | Actual: Healthy | ✔\n",
            "File: S_36.jpg | Predicted: Sick | Actual: Sick | ✔\n",
            "File: S_72.jpg | Predicted: Healthy | Actual: Sick | ✘\n",
            "File: 18.jpg | Predicted: Healthy | Actual: Healthy | ✔\n",
            "File: S_34.jpg | Predicted: Sick | Actual: Sick | ✔\n",
            "File: 37.jpg | Predicted: Sick | Actual: Healthy | ✘\n",
            "File: S_38.jpg | Predicted: Healthy | Actual: Sick | ✘\n",
            "File: S_49.jpg | Predicted: Sick | Actual: Sick | ✔\n",
            "File: 27.jpg | Predicted: Healthy | Actual: Healthy | ✔\n",
            "File: 13.jpg | Predicted: Healthy | Actual: Healthy | ✔\n",
            "File: 14.jpg | Predicted: Healthy | Actual: Healthy | ✔\n",
            "File: S_35.jpg | Predicted: Sick | Actual: Sick | ✔\n",
            "File: 26.jpg | Predicted: Sick | Actual: Healthy | ✘\n",
            "File: S_43.jpg | Predicted: Sick | Actual: Sick | ✔\n",
            "File: S_61.jpg | Predicted: Healthy | Actual: Sick | ✘\n",
            "File: S_70.jpg | Predicted: Sick | Actual: Sick | ✔\n",
            "File: S_69.jpg | Predicted: Healthy | Actual: Sick | ✘\n",
            "File: S_65.jpg | Predicted: Sick | Actual: Sick | ✔\n",
            "File: 6.jpg | Predicted: Healthy | Actual: Healthy | ✔\n",
            "File: S_40.jpg | Predicted: Sick | Actual: Sick | ✔\n",
            "File: S_51.jpg | Predicted: Sick | Actual: Sick | ✔\n",
            "File: S_53.jpg | Predicted: Sick | Actual: Sick | ✔\n",
            "File: S_50.jpg | Predicted: Sick | Actual: Sick | ✔\n",
            "File: S_48.jpg | Predicted: Sick | Actual: Sick | ✔\n",
            "File: 19.jpg | Predicted: Healthy | Actual: Healthy | ✔\n",
            "File: 12.jpg | Predicted: Healthy | Actual: Healthy | ✔\n",
            "File: 1.jpg | Predicted: Healthy | Actual: Healthy | ✔\n",
            "File: S_66.jpg | Predicted: Sick | Actual: Sick | ✔\n",
            "File: S_60.jpg | Predicted: Sick | Actual: Sick | ✔\n",
            "File: S_45.jpg | Predicted: Sick | Actual: Sick | ✔\n",
            "File: S_57.jpg | Predicted: Sick | Actual: Sick | ✔\n",
            "File: 21.jpg | Predicted: Healthy | Actual: Healthy | ✔\n",
            "File: 5.jpg | Predicted: Healthy | Actual: Healthy | ✔\n",
            "File: 29.jpg | Predicted: Sick | Actual: Healthy | ✘\n",
            "File: 24.jpg | Predicted: Healthy | Actual: Healthy | ✔\n",
            "File: 30.jpg | Predicted: Healthy | Actual: Healthy | ✔\n",
            "File: S_73.jpg | Predicted: Sick | Actual: Sick | ✔\n",
            "File: S_42.jpg | Predicted: Sick | Actual: Sick | ✔\n",
            "File: 10.jpg | Predicted: Healthy | Actual: Healthy | ✔\n",
            "File: 7.jpg | Predicted: Healthy | Actual: Healthy | ✔\n",
            "File: 9.jpg | Predicted: Healthy | Actual: Healthy | ✔\n",
            "File: 32.jpg | Predicted: Sick | Actual: Healthy | ✘\n",
            "File: 36.jpg | Predicted: Healthy | Actual: Healthy | ✔\n",
            "File: S_12.jpg | Predicted: Healthy | Actual: Sick | ✘\n",
            "File: S_52.jpg | Predicted: Sick | Actual: Sick | ✔\n",
            "File: S_68.jpg | Predicted: Healthy | Actual: Sick | ✘\n",
            "File: 15.jpg | Predicted: Healthy | Actual: Healthy | ✔\n",
            "File: 35.jpg | Predicted: Healthy | Actual: Healthy | ✔\n",
            "File: S_37.jpg | Predicted: Healthy | Actual: Sick | ✘\n",
            "File: 25.jpg | Predicted: Sick | Actual: Healthy | ✘\n",
            "File: 23.jpg | Predicted: Sick | Actual: Healthy | ✘\n",
            "File: 20.jpg | Predicted: Healthy | Actual: Healthy | ✔\n",
            "File: 33.jpg | Predicted: Sick | Actual: Healthy | ✘\n",
            "File: S_74.jpg | Predicted: Sick | Actual: Sick | ✔\n",
            "File: S_56.jpg | Predicted: Sick | Actual: Sick | ✔\n",
            "File: S_39.jpg | Predicted: Sick | Actual: Sick | ✔\n",
            "File: S_41.jpg | Predicted: Sick | Actual: Sick | ✔\n",
            "File: 4.jpg | Predicted: Healthy | Actual: Healthy | ✔\n",
            "File: S_64.jpg | Predicted: Healthy | Actual: Sick | ✘\n",
            "File: 31.jpg | Predicted: Sick | Actual: Healthy | ✘\n",
            "File: S_46.jpg | Predicted: Sick | Actual: Sick | ✔\n",
            "File: S_63.jpg | Predicted: Healthy | Actual: Sick | ✘\n",
            "File: S_71.jpg | Predicted: Healthy | Actual: Sick | ✘\n",
            "File: 11.jpg | Predicted: Healthy | Actual: Healthy | ✔\n",
            "File: S_54.jpg | Predicted: Sick | Actual: Sick | ✔\n",
            "File: 17.jpg | Predicted: Healthy | Actual: Healthy | ✔\n",
            "File: S_47.jpg | Predicted: Sick | Actual: Sick | ✔\n",
            "File: 22.jpg | Predicted: Healthy | Actual: Healthy | ✔\n",
            "File: 8.jpg | Predicted: Healthy | Actual: Healthy | ✔\n",
            "File: 2.jpg | Predicted: Healthy | Actual: Healthy | ✔\n",
            "File: 28.jpg | Predicted: Healthy | Actual: Healthy | ✔\n",
            "File: S_44.jpg | Predicted: Sick | Actual: Sick | ✔\n",
            "File: 39.jpg | Predicted: Healthy | Actual: Healthy | ✔\n",
            "\n",
            "Test Accuracy: 75.00% (60/80 correct)\n"
          ]
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(\"Model.pth\"))\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "test_images = [f for f in os.listdir(test_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "print(f\"\\nFound {len(test_images)} test images.\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    for filename in test_images:\n",
        "        file_path = os.path.join(test_dir, filename)\n",
        "        image = default_loader(file_path)\n",
        "        image = val_test_transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "        output = model(image).squeeze()\n",
        "        pred = (torch.sigmoid(output) > 0.5).long().item()\n",
        "        actual_label = 1 if filename.lower().startswith(\"s_\") else 0\n",
        "        is_correct = (pred == actual_label)\n",
        "        correct += is_correct\n",
        "        total += 1\n",
        "\n",
        "        pred_label_text = \"Sick\" if pred == 1 else \"Healthy\"\n",
        "        actual_label_text = \"Sick\" if actual_label == 1 else \"Healthy\"\n",
        "        print(f\"File: {filename} | Predicted: {pred_label_text} | Actual: {actual_label_text} | {'✔' if is_correct else '✘'}\")\n",
        "\n",
        "accuracy = (correct / total) * 100\n",
        "print(f\"\\nTest Accuracy: {accuracy:.2f}% ({correct}/{total} correct)\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
